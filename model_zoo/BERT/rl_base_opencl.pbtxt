# Compared to standard:
# 1. 12 attention heads vs 4
# 2. Hidden size is 768 vs 1024
# 3. Intermediate size is 768 vs 1024
# 4. warmup is 10,000 vs 5,000
# 5. dupe factor is 20 instead of 50
# 6. There can be up to 3 holes.
# 7. Holes can be up to 10 tokens long.
# 8. Learning rate increased to 45 from 40.
working_dir: "AST" ## This path is relative to "workspace_dir", which is an app FLAG
rl_model {
  train_set: true
  agent {
    num_epochs: 500
    num_episodes: 16
    steps_per_episode: 128
    num_updates: 20
    gamma: 0.99
    lam: 0.95
    epsilon: 0.1
    learning_rate_micros: 240
    value_loss_coefficient: 0.5
    entropy_coefficient: 0.05
    batch_size: 1
    action_temperature_micros: 700000
    token_temperature_micros: 700000
    feature_tokenizer {
      feature_max_value_token: 32768
      feature_singular_token_thr: 512
      feature_token_range: 2048
      feature_sequence_length: 256
    }
  }
  language_model{
    corpus {
      local_tar_archive: "$PWD/../corpus/ultimate_corpus.tar.bz2"
      tokenizer {
        token_type: "ast"
        token_list: "deeplearning/clgen/corpuses/token_lists.json"
        mask_tokens: true
        wordpiece_tokenization: false
      }
      contentfile_separator: "\n\n\n\n"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:ClangPreprocessWithShim"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:StripDoubleUnderscorePrefixes"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:ClangFormat"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:InvertKernelSpecifier"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:ExtractOnlySingleKernels"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:StringKernelsToSource"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:Compile"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:NormalizeIdentifiers"
      preprocessor: "deeplearning.benchpress.preprocessors.common:StripDuplicateEmptyLines"
      preprocessor: "deeplearning.benchpress.preprocessors.common:StripMultipleWhitespaces"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:SanitizeKernelPrototype"
      preprocessor: "deeplearning.benchpress.preprocessors.common:StripTrailingWhitespace"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:ClangFormat"
      preprocessor: "deeplearning.benchpress.preprocessors.common:MinimumLineCount3"
      preprocessor: "deeplearning.benchpress.preprocessors.opencl:Compile"
    }
    architecture {
      backend: TORCH_BERT
      hidden_size: 768
      num_hidden_layers: 4
      num_attention_heads: 12
      intermediate_size: 3072
      hidden_act: "gelu"
      hidden_dropout_prob: 0.1
      attention_probs_dropout_prob: 0.1
      max_position_embeddings: 256
      layer_norm_eps: 1e-12
      type_vocab_size: 16
      initializer_range: 0.02
    }
    training {
      num_train_steps: 3000000
      num_warmup_steps: 100000
      sequence_length: 256
      batch_size: 16
      max_predictions_per_seq: 1
      dupe_factor: 1
      masked_lm_prob: 0.4
      random_seed: 12345
      shuffle_corpus_contentfiles_between_epochs: true
      data_generator {
        datapoint_type: "kernel"
        datapoint_time: "online"
        use_start_end : true
        truncate_large_kernels: true
        steps_per_epoch: 20000
        validation_split: 0
        hole {
          relative_length: 1.0
          uniform_distribution: true
          stage_training: false
        }
      }
      adam_optimizer {
        initial_learning_rate_micros: 45  # = 0.02 real value
      }
    }
  }
}
# sampler {
#   live_sampling: true
#   batch_size: 4
#   sequence_length: 768
#   temperature_micros: 800000  # = 0.8 real value
#   termination_criteria {
#     maxlen {
#       maximum_tokens_in_sample: 768
#     }
#   }
# }
sampler {
  start_text: "[START]kernel void [HOLE]}[END]"
  batch_size: 16
  sequence_length: 1024
  temperature_micros: 700000  # = 0.8 real value
  termination_criteria {
    maxlen {
      maximum_tokens_in_sample: 1024
    }
  }
}
# sampler {
#   sample_corpus {
#     corpus_config {
#       active {
#         target: "rodinia"
#         active_limit_per_feed: 2000
#         active_search_depth: 100
#         active_search_width: 32
#         batch_size_per_feed: 2
#         active_dropout_prob: 0.1
#         feature_space: "GreweFeatures"
#       }
#       max_predictions_per_seq: 1
#       masked_lm_prob: 0.6
#       hole {
#         relative_length: 0.45
#         uniform_distribution: true
#       }
#     }
#     start_text: "[START]kernel void [HOLE]}[END]"
#   }
#   batch_size: 64
#   sequence_length: 1024
#   temperature_micros: 700000  # = 0.8 real value
#   termination_criteria {
#     maxlen {
#       maximum_tokens_in_sample: 1024
#     }
#   }
# }
