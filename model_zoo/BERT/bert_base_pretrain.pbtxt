working_dir: "Base_BERT" ## This path is relative to "workspace_dir", which is an app FLAG
language_model {
  pre_train_corpus {
    bq_database: "/private/home/foivos/clgen_c_github.db"
    contentfile_separator: "\n\n\n\n"
    preprocessor: "deeplearning.clgen.preprocessors.c:StripIncludes"
    preprocessor: "deeplearning.clgen.preprocessors.c:ClangPreprocess"
    preprocessor: "deeplearning.clgen.preprocessors.c:ExtractFunctions"
    preprocessor: "deeplearning.clgen.preprocessors.c:Compile"
    preprocessor: "deeplearning.clgen.preprocessors.c:NormalizeIdentifiers"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:StripDoubleUnderscorePrefixes"
    preprocessor: "deeplearning.clgen.preprocessors.c:ClangFormat"
    preprocessor: "deeplearning.clgen.preprocessors.common:MinimumLineCount3"
  }
  corpus {
    local_tar_archive: "$PWD/../corpus/ultimate_corpus.tar.bz2"
    tokenizer {
      token_type: "ast"
      token_list: "deeplearning/clgen/corpuses/token_lists.json"
      mask_tokens: true
      wordpiece_tokenization: false
    }
    contentfile_separator: "\n\n\n\n"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:ClangPreprocessWithShim"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:StripDoubleUnderscorePrefixes"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:ClangFormat"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:InvertKernelSpecifier"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:ExtractOnlySingleKernels"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:StringKernelsToSource"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:Compile"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:NormalizeIdentifiers"
    preprocessor: "deeplearning.clgen.preprocessors.common:StripDuplicateEmptyLines"
    preprocessor: "deeplearning.clgen.preprocessors.common:StripMultipleWhitespaces"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:SanitizeKernelPrototype"
    preprocessor: "deeplearning.clgen.preprocessors.common:StripTrailingWhitespace"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:ClangFormat"
    preprocessor: "deeplearning.clgen.preprocessors.common:MinimumLineCount3"
    preprocessor: "deeplearning.clgen.preprocessors.opencl:Compile"
  }
  architecture {
    backend: TORCH_BERT
    hidden_size: 768
    num_hidden_layers: 12
    num_attention_heads: 12
    intermediate_size: 3072
    hidden_act: "gelu"
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
    max_position_embeddings: 768
    type_vocab_size: 2
    initializer_range: 0.02
    layer_norm_eps: 1e-12
  }
  training {
    num_train_steps: 8000000
    num_pretrain_steps: 16000000
    num_warmup_steps: 50000
    num_prewarmup_steps: 50000
    sequence_length: 768
    batch_size: 64
    max_predictions_per_seq: 1
    dupe_factor: 1
    masked_lm_prob: 0.9
    random_seed: 12345
    shuffle_corpus_contentfiles_between_epochs: true
    data_generator {
      datapoint_type: "kernel"
      datapoint_time: "online"
      use_start_end : true
      truncate_large_kernels: true
      steps_per_epoch: 400000
      validation_split: 10
      hole {
        relative_length: 1.0
        uniform_distribution: true
        stage_training: false
      }
    }
    adam_optimizer {
      initial_learning_rate_micros: 100  # = 1e-4 real value
    }
  }
}
sampler {
  start_text: "kernel void [HOLE]"
  batch_size: 8
  sequence_length: 768
  temperature_micros: 800000  # = 0.8 real value
  termination_criteria {
    maxlen {
      maximum_tokens_in_sample: 768
    }
  }
}
