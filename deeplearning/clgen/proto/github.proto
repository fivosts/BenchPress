// Protocol buffers used for organizing mass-clones of GitHub repos.
//
// Copyright 2020 Foivos Tsimpourlas <F.Tsimpourlas@sms.ed.ac.uk>.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto2";

package github;

// Base specification of a github miner
message GithubMiner {
  enum DataFormat {
    // zip file
    zip     = 0;
    // folder with files
    folder  = 1;
    // folder of multiple json files (equivalent data w/ sql)
    json    = 2;
    // Multiple json files, each one compressed to maximum to save space.
    jsonzip = 3;
    // sqlite db
    sql     = 4;
    // BigQuery remote table
    bq      = 5;
  }
  oneof miner {
    // BigQuery API
    BigQuery  big_query = 4;
    // Exhaustive request miner
    Recursive recursive = 5;
  }
  // Select to export finalized corpus
  optional ExportCorpus export_corpus = 6;
  // Base path of miner's data storage.
  optional string path = 7;
  // Format of saved data.
  optional DataFormat data_format = 8;
}

message BigQuery {
  // Path to json file with BQ account credentials.
  // Defaulted to clgen/deeplearning/clgen/corpuses/BigQuery_credentials.json
  optional string credentials = 1;
  optional string language    = 2;
}

message Recursive {
  // Github access tokens
  optional string access_token = 1;
  // number of files per flush in thousands
  optional int32 flush_limit_K = 2;
  // total corpus limit in thousands.
  optional int32 corpus_size_K = 3;
}

message ExportCorpus {
  enum DataFormat {
    // zip file
    zip     = 0;
    // folder with files
    folder  = 1;
    // folder of multiple json files (equivalent data w/ sql)
    json    = 2;
    // Multiple json files, each one compressed to maximum to save space.
    jsonzip = 3;
    // sqlite db
    sql     = 4;
    // BigQuery remote table
    bq      = 5;
  }
  optional bool inline_headers = 6;
}