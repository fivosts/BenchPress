// The file defines the protos for specificying Active learning commmittee for
// query by committee sampling.
syntax = "proto2";

package clgen;

option go_package = "clgenpb";
option java_multiple_files = true;
option java_outer_classname = "ActiveLearningProto";
option java_package = "com.clgen";

message ActiveLearner {
  optional Committee committee       = 1;
  optional string    downstream_task = 2;
  optional string    training_corpus = 3;
  optional int32     random_seed     = 4;
}

// Committee is a list of models.
message Committee {
  repeated MLP    mlp     = 1;
  repeated KMeans k_means = 2;
  repeated KNN    knn     = 3;
  // repeated <ModelType> model_type = x;
}

// MLP-type architecture.
message MLP {
  repeated Layer layer                        = 1;
  optional float initial_learning_rate_micros = 2;
  optional int32 batch_size                   = 3;
  optional int32 num_train_steps              = 4;
  optional int32 num_warmup_steps             = 5;
}

// KMeans type architecture.
// See scitkit-learn specs for parameters below.
message KMeans {
  optional int32  n_clusters = 1;
  optional string init       = 2;
  optional int32  n_init     = 3;
  optional int32  max_iter   = 4;
  optional float  tol        = 5;
  optional string algorithm  = 6;
}

// kNN architeture.
message KNN {
  optional int32  n_neighbors = 1;
  optional string weights     = 2;
  optional string algorithm   = 3;
  optional int32  leaf_size   = 4;
  optional float  p           = 5;
}

// Layer wrapper to help with layer's ordering consistency.
message Layer {
  oneof layers {
    Embedding embedding  = 1;
    Linear    linear     = 2;
    Dropout   dropout    = 3;
    LayerNorm layer_norm = 4;
    ACT_fn    act_fn     = 5;
  }
}

// Input embeddings are usually very useful.
message Embedding {
  optional int32 num_embeddings = 1;
  optional int32 embedding_dim  = 2;
  optional int32 padding_idx    = 3;
}

// Linear specs.
message Linear {
  optional int32 in_features  = 1;
  optional int32 out_features = 2;
}

// Dropout Specs.
message Dropout {
  optional float dropout_prob = 1;
}

// LayerNorm specs.
message LayerNorm {
  optional float eps = 1;
}

// Activation function specs.
message ACT_fn {
  // Name of activation function.
  optional string fn = 1;
}